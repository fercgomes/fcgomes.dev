---
title: "How I Almost Nuked Fokvs Out of Its Existence"
description: "The story of how I almost destroyed Fokvs by corrupting our Fly.io Postgres instance during a database migration. A cautionary tale about data migrations and infrastructure scaling."
date: "2025-01-15"
lang: "en"
author: "Fernando Gomes"
tags:
  ["Database", "PostgreSQL", "Migration", "DevOps", "Lessons Learned", "Fly.io"]
aiGenerated: false
---

# How I Almost Nuked Fokvs Out of Its Existence

This is the story of how I almost nuked Fokvs out of its existence by corrupting our Fly.io Postgres instance ðŸ‘‡

We had this idea of changing the user interaction mechanism from like/dislike to a 1-5 star rating, to reduce the cognitive load users had to go through in order to scan content for quality. So, I create the new tables and fields in our database. One table to associate users with ratings, and fields in the documents table for average rating and rating count.

That being done, time to migrate likes and dislikes into 1 - 5 ratings. _Easy peasy._ Now comes the backfills for average rating and rating count. Iterate over 15k rows, averaging and counting tens of thousands of users interactions over each one of them shouldn't be that bad right?

I look at our Grafana metrics and our humble PG instance with its 1vCPU and a couple of megs of RAM is sweating profusely. CPU usage is through the roof, and Fly is throttling us. Killed the queries, restarted the instance and started over. Same thing. Once the query is running, the database just becomes completely unresponsive.

After the fifth restart, everything just becomes unresponsive. Restarting the instance doesn't work. Machine screams an error I had never seen before, at every restart. So, the entire platform becomes unresponsive. Users start to complain. It's late at night and I just can't believe this is happening. **I'm cooked, right?**

After trying to cope with the situation for a while, I accept my fate and start reading the documentation on snapshot restoration. _Nope._ Doesn't work. **I am definitely cooked now.**

After going through documentation again, I realized I could just take one of earlier working snapshots (3 hours of data loss) and attach it to a fresh instance, so I try that. Machine is working, health checks are passing, so I switch the database URL in the API to this new machine, and **boom: everything working again.**

Now, all I have to do is scaled the PG instances to avoid the shared CPU throttling and run the backfills. All good.

**I'm never skimping on data migrations never again.**
